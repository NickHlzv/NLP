{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим предобработку данных с Твиттера, чтобы отчищенный данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания.\n",
    "Для работы объединим train_df и test_df.\n",
    "\n",
    "Задания:\n",
    "\n",
    "1) Заменим html-сущности (к примеру: &lt; &gt; &amp;). \"&lt;\" заменим на “<” и \"&amp;\" заменим на “&”)\"\"\". Сделаем это с помощью HTMLParser.unescape(). Всю предобработку делаем в новом столбце 'clean_tweet'\n",
    "\n",
    "2) Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n",
    "при применении функции необходимо использовать np.vectorize(function).\n",
    "\n",
    "3) Изменим регистр твитов на нижний с помощью .lower().\n",
    "\n",
    "4) Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова).\n",
    "\n",
    "5) Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
    "\n",
    "6) Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
    "\n",
    "7) Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
    "\n",
    "8) Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
    "\n",
    "9) Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'.\n",
    "\n",
    "10) Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1]).\n",
    "\n",
    "11) Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'.\n",
    "\n",
    "12) Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов.\n",
    "\n",
    "13) Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга.\n",
    "\n",
    "14) Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации.\n",
    "\n",
    "15) Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}\n",
    "\n",
    "\n",
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "import html\n",
    "from copy import copy\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id  label                                              tweet\n0   1      0   @user when a father is dysfunctional and is s...\n1   2      0  @user @user thanks for #lyft credit i can't us...\n2   3      0                                bihday your majesty\n3   4      0  #model   i love u take with u all the time in ...\n4   5      0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_tweets.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      id                                              tweet\n0  31963  #studiolife #aislife #requires #passion #dedic...\n1  31964   @user #white #supremacists want everyone to s...\n2  31965  safe ways to heal your #acne!!    #altwaystohe...\n3  31966  is the hp and the cursed child book up for res...\n4  31967    3rd #bihday to my amazing, hilarious #nephew...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31963</td>\n      <td>#studiolife #aislife #requires #passion #dedic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31964</td>\n      <td>@user #white #supremacists want everyone to s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31965</td>\n      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31966</td>\n      <td>is the hp and the cursed child book up for res...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31967</td>\n      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_tweets.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   id  label                                              tweet\n0   1    0.0   @user when a father is dysfunctional and is s...\n1   2    0.0  @user @user thanks for #lyft credit i can't us...\n2   3    0.0                                bihday your majesty\n3   4    0.0  #model   i love u take with u all the time in ...\n4   5    0.0             factsguide: society now    #motivation",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = train_df.append(test_df, ignore_index = True, sort = False)\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      49159 non-null  int64  \n",
      " 1   label   31962 non-null  float64\n",
      " 2   tweet   49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0   @user when a father is dysfunctional and is s...\n1          2    0.0  @user @user thanks for #lyft credit i can't us...\n2          3    0.0                                bihday your majesty\n3          4    0.0  #model   i love u take with u all the time in ...\n4          5    0.0             factsguide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thought factory: left-right polarisation! #tru...\n49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...\n49157  49158    NaN  happy, at work conference: right mindset leads...\n49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Заменим html-сущности (к примеру: &lt; &gt; &amp;). \"&lt;\" заменим на “<” и \"&amp;\" заменим на “&”)\"\"\". Сделаем это с помощью HTMLParser.unescape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0   @user when a father is dysfunctional and is s...\n1          2    0.0  @user @user thanks for #lyft credit i can't us...\n2          3    0.0                                bihday your majesty\n3          4    0.0  #model   i love u take with u all the time in ...\n4          5    0.0             factsguide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thought factory: left-right polarisation! #tru...\n49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) & u...\n49157  49158    NaN  happy, at work conference: right mindset leads...\n49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combine_df.copy()\n",
    "df['tweet'] = df['tweet'].apply(html.unescape)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n",
    "при применении функции необходимо использовать np.vectorize(function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a father is dysfunctional and is so se...\n1          2    0.0      thanks for #lyft credit i can't use cause ...\n2          3    0.0                                bihday your majesty\n3          4    0.0  #model   i love u take with u all the time in ...\n4          5    0.0             factsguide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thought factory: left-right polarisation! #tru...\n49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) & u...\n49157  49158    NaN  happy, at work conference: right mindset leads...\n49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a father is dysfunctional and is so se...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks for #lyft credit i can't use cause ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def del_user(input_text):\n",
    "    return re.sub('@[\\w]*', ' ', input_text)\n",
    "df['tweet'] = df['tweet'].apply(del_user)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Изменим регистр твитов на нижний с помощью .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a father is dysfunctional and is so se...\n1          2    0.0      thanks for #lyft credit i can't use cause ...\n2          3    0.0                                bihday your majesty\n3          4    0.0  #model   i love u take with u all the time in ...\n4          5    0.0             factsguide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thought factory: left-right polarisation! #tru...\n49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) & u...\n49157  49158    NaN  happy, at work conference: right mindset leads...\n49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a father is dysfunctional and is so se...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks for #lyft credit i can't use cause ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [txt.lower() for txt in df['tweet']]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a father is dysfunctional and is so se...\n1          2    0.0      thanks for #lyft credit i cannot use cause...\n2          3    0.0                                bihday your majesty\n3          4    0.0  #model   i love u take with u all the time in ...\n4          5    0.0             factsguide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thought factory: left-right polarisation! #tru...\n49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...\n49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) & u...\n49157  49158    NaN  happy, at work conference: right mindset leads...\n49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a father is dysfunctional and is so se...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks for #lyft credit i cannot use cause...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp; u...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_word(text, dictionary):\n",
    "    regexp = \"|\".join(re.escape(k) for k in dictionary)\n",
    "    return re.sub(regexp, lambda m: dictionary[m.group(0)], text)\n",
    "df['tweet'] = [replace_word(text, apostrophe_dict) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a fatheare is dysfyounctional and is s...\n1          2    0.0      thanks foare #lyft careedit i cannot youse...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0  #model   i love you take with you all the time...\n4          5    0.0        factsgrinyouide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey: left-areigrinht polaar...\n49155  49156    NaN  feelingrin like a mearemaid ð #haiareflip #...\n49156  49157    NaN  #hillaarey #campaigrinned today in #ohio((oh m...\n49157  49158    NaN  happy, at woarek confeareence: areigrinht mind...\n49158  49159    NaN  my   songrin \"so grinlad\" fareee download!  #s...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a fatheare is dysfyounctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare #lyft careedit i cannot youse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love you take with you all the time...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey: left-areigrinht polaar...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like a mearemaid ð #haiareflip #...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillaarey #campaigrinned today in #ohio((oh m...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at woarek confeareence: areigrinht mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   songrin \"so grinlad\" fareee download!  #s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [replace_word(text, short_word_dict) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a fatheare is dysfyounctional and is s...\n1          2    0.0      thanks foare #lyft careedit i cannot youse...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0  #model   i love you take with you all the time...\n4          5    0.0        factsgrinyouide: society now    #motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey: left-areigrinht polaar...\n49155  49156    NaN  feelingrin like a mearemaid ð #haiareflip #...\n49156  49157    NaN  #hillaarey #campaigrinned today in #ohio((oh m...\n49157  49158    NaN  happy, at woarek confeareence: areigrinht mind...\n49158  49159    NaN  my   songrin \"so grinlad\" fareee download!  #s...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a fatheare is dysfyounctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare #lyft careedit i cannot youse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>#model   i love you take with you all the time...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide: society now    #motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey: left-areigrinht polaar...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like a mearemaid ð #haiareflip #...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>#hillaarey #campaigrinned today in #ohio((oh m...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy, at woarek confeareence: areigrinht mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   songrin \"so grinlad\" fareee download!  #s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [replace_word(text, emoticon_dict) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a fatheare is dysfyounctional and is s...\n1          2    0.0      thanks foare  lyft careedit i cannot youse...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0   model   i love you take with you all the time...\n4          5    0.0        factsgrinyouide  society now     motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey  left areigrinht polaar...\n49155  49156    NaN  feelingrin like a mearemaid ð     haiareflip  ...\n49156  49157    NaN   hillaarey  campaigrinned today in  ohio  oh m...\n49157  49158    NaN  happy  at woarek confeareence  areigrinht mind...\n49158  49159    NaN  my   songrin  so grinlad  fareee download    s...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a fatheare is dysfyounctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare  lyft careedit i cannot youse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model   i love you take with you all the time...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide  society now     motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey  left areigrinht polaar...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like a mearemaid ð     haiareflip  ...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey  campaigrinned today in  ohio  oh m...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy  at woarek confeareence  areigrinht mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   songrin  so grinlad  fareee download    s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [re.sub(r'[^\\w\\s]', ' ', text) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a fatheare is dysfyounctional and is s...\n1          2    0.0      thanks foare  lyft careedit i cannot youse...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0   model   i love you take with you all the time...\n4          5    0.0        factsgrinyouide  society now     motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey  left areigrinht polaar...\n49155  49156    NaN  feelingrin like a mearemaid       haiareflip  ...\n49156  49157    NaN   hillaarey  campaigrinned today in  ohio  oh m...\n49157  49158    NaN  happy  at woarek confeareence  areigrinht mind...\n49158  49159    NaN  my   songrin  so grinlad  fareee download    s...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a fatheare is dysfyounctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare  lyft careedit i cannot youse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model   i love you take with you all the time...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide  society now     motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey  left areigrinht polaar...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like a mearemaid       haiareflip  ...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey  campaigrinned today in  ohio  oh m...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy  at woarek confeareence  areigrinht mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   songrin  so grinlad  fareee download    s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [re.sub(r'[^a-zA-Z0-9]', ' ', text) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0     when a fatheare is dysfyounctional and is s...\n1          2    0.0      thanks foare  lyft careedit i cannot youse...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0   model   i love you take with you all the time...\n4          5    0.0        factsgrinyouide  society now     motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey  left areigrinht polaar...\n49155  49156    NaN  feelingrin like a mearemaid       haiareflip  ...\n49156  49157    NaN   hillaarey  campaigrinned today in  ohio  oh m...\n49157  49158    NaN  happy  at woarek confeareence  areigrinht mind...\n49158  49159    NaN  my   songrin  so grinlad  fareee download    s...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when a fatheare is dysfyounctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare  lyft careedit i cannot youse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model   i love you take with you all the time...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide  society now     motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey  left areigrinht polaar...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like a mearemaid       haiareflip  ...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey  campaigrinned today in  ohio  oh m...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy  at woarek confeareence  areigrinht mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my   songrin  so grinlad  fareee download    s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [re.sub(r'[^a-zA-Z]', ' ', text) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet\n0          1    0.0  when fatheare is dysfyounctional and is so sel...\n1          2    0.0  thanks foare lyft careedit cannot youse cayous...\n2          3    0.0                            bihday yoyouare majesty\n3          4    0.0  model love you take with you all the time in y...\n4          5    0.0             factsgrinyouide society now motivation\n...      ...    ...                                                ...\n49154  49155    NaN  thoyougrinht factoarey left areigrinht polaare...\n49155  49156    NaN  feelingrin like mearemaid haiareflip nevearear...\n49156  49157    NaN  hillaarey campaigrinned today in ohio oh my go...\n49157  49158    NaN  happy at woarek confeareence areigrinht mindse...\n49158  49159    NaN  my songrin so grinlad fareee download shoegrin...\n\n[49159 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when fatheare is dysfyounctional and is so sel...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare lyft careedit cannot youse cayous...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in y...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide society now motivation</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey left areigrinht polaare...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like mearemaid haiareflip nevearear...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey campaigrinned today in ohio oh my go...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy at woarek confeareence areigrinht mindse...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my songrin so grinlad fareee download shoegrin...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'] = [' '.join([w for w in x.split() if len(w)>1]) for x in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet  \\\n0          1    0.0  when fatheare is dysfyounctional and is so sel...   \n1          2    0.0  thanks foare lyft careedit cannot youse cayous...   \n2          3    0.0                            bihday yoyouare majesty   \n3          4    0.0  model love you take with you all the time in y...   \n4          5    0.0             factsgrinyouide society now motivation   \n...      ...    ...                                                ...   \n49154  49155    NaN  thoyougrinht factoarey left areigrinht polaare...   \n49155  49156    NaN  feelingrin like mearemaid haiareflip nevearear...   \n49156  49157    NaN  hillaarey campaigrinned today in ohio oh my go...   \n49157  49158    NaN  happy at woarek confeareence areigrinht mindse...   \n49158  49159    NaN  my songrin so grinlad fareee download shoegrin...   \n\n                                             tweet_token  \n0      [when, fatheare, is, dysfyounctional, and, is,...  \n1      [thanks, foare, lyft, careedit, can, not, yous...  \n2                            [bihday, yoyouare, majesty]  \n3      [model, love, you, take, with, you, all, the, ...  \n4            [factsgrinyouide, society, now, motivation]  \n...                                                  ...  \n49154  [thoyougrinht, factoarey, left, areigrinht, po...  \n49155  [feelingrin, like, mearemaid, haiareflip, neve...  \n49156  [hillaarey, campaigrinned, today, in, ohio, oh...  \n49157  [happy, at, woarek, confeareence, areigrinht, ...  \n49158  [my, songrin, so, grinlad, fareee, download, s...  \n\n[49159 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when fatheare is dysfyounctional and is so sel...</td>\n      <td>[when, fatheare, is, dysfyounctional, and, is,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare lyft careedit cannot youse cayous...</td>\n      <td>[thanks, foare, lyft, careedit, can, not, yous...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n      <td>[bihday, yoyouare, majesty]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in y...</td>\n      <td>[model, love, you, take, with, you, all, the, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide society now motivation</td>\n      <td>[factsgrinyouide, society, now, motivation]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey left areigrinht polaare...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like mearemaid haiareflip nevearear...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey campaigrinned today in ohio oh my go...</td>\n      <td>[hillaarey, campaigrinned, today, in, ohio, oh...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy at woarek confeareence areigrinht mindse...</td>\n      <td>[happy, at, woarek, confeareence, areigrinht, ...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my songrin so grinlad fareee download shoegrin...</td>\n      <td>[my, songrin, so, grinlad, fareee, download, s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_token'] = [nltk.tokenize.word_tokenize(text) for text in df.tweet]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['i',\n 'me',\n 'my',\n 'myself',\n 'we',\n 'our',\n 'ours',\n 'ourselves',\n 'you',\n \"you're\",\n \"you've\",\n \"you'll\",\n \"you'd\",\n 'your',\n 'yours',\n 'yourself',\n 'yourselves',\n 'he',\n 'him',\n 'his',\n 'himself',\n 'she',\n \"she's\",\n 'her',\n 'hers',\n 'herself',\n 'it',\n \"it's\",\n 'its',\n 'itself',\n 'they',\n 'them',\n 'their',\n 'theirs',\n 'themselves',\n 'what',\n 'which',\n 'who',\n 'whom',\n 'this',\n 'that',\n \"that'll\",\n 'these',\n 'those',\n 'am',\n 'is',\n 'are',\n 'was',\n 'were',\n 'be',\n 'been',\n 'being',\n 'have',\n 'has',\n 'had',\n 'having',\n 'do',\n 'does',\n 'did',\n 'doing',\n 'a',\n 'an',\n 'the',\n 'and',\n 'but',\n 'if',\n 'or',\n 'because',\n 'as',\n 'until',\n 'while',\n 'of',\n 'at',\n 'by',\n 'for',\n 'with',\n 'about',\n 'against',\n 'between',\n 'into',\n 'through',\n 'during',\n 'before',\n 'after',\n 'above',\n 'below',\n 'to',\n 'from',\n 'up',\n 'down',\n 'in',\n 'out',\n 'on',\n 'off',\n 'over',\n 'under',\n 'again',\n 'further',\n 'then',\n 'once',\n 'here',\n 'there',\n 'when',\n 'where',\n 'why',\n 'how',\n 'all',\n 'any',\n 'both',\n 'each',\n 'few',\n 'more',\n 'most',\n 'other',\n 'some',\n 'such',\n 'no',\n 'nor',\n 'not',\n 'only',\n 'own',\n 'same',\n 'so',\n 'than',\n 'too',\n 'very',\n 's',\n 't',\n 'can',\n 'will',\n 'just',\n 'don',\n \"don't\",\n 'should',\n \"should've\",\n 'now',\n 'd',\n 'll',\n 'm',\n 'o',\n 're',\n 've',\n 'y',\n 'ain',\n 'aren',\n \"aren't\",\n 'couldn',\n \"couldn't\",\n 'didn',\n \"didn't\",\n 'doesn',\n \"doesn't\",\n 'hadn',\n \"hadn't\",\n 'hasn',\n \"hasn't\",\n 'haven',\n \"haven't\",\n 'isn',\n \"isn't\",\n 'ma',\n 'mightn',\n \"mightn't\",\n 'mustn',\n \"mustn't\",\n 'needn',\n \"needn't\",\n 'shan',\n \"shan't\",\n 'shouldn',\n \"shouldn't\",\n 'wasn',\n \"wasn't\",\n 'weren',\n \"weren't\",\n 'won',\n \"won't\",\n 'wouldn',\n \"wouldn't\"]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet  \\\n0          1    0.0  when fatheare is dysfyounctional and is so sel...   \n1          2    0.0  thanks foare lyft careedit cannot youse cayous...   \n2          3    0.0                            bihday yoyouare majesty   \n3          4    0.0  model love you take with you all the time in y...   \n4          5    0.0             factsgrinyouide society now motivation   \n...      ...    ...                                                ...   \n49154  49155    NaN  thoyougrinht factoarey left areigrinht polaare...   \n49155  49156    NaN  feelingrin like mearemaid haiareflip nevearear...   \n49156  49157    NaN  hillaarey campaigrinned today in ohio oh my go...   \n49157  49158    NaN  happy at woarek confeareence areigrinht mindse...   \n49158  49159    NaN  my songrin so grinlad fareee download shoegrin...   \n\n                                             tweet_token  \\\n0      [when, fatheare, is, dysfyounctional, and, is,...   \n1      [thanks, foare, lyft, careedit, can, not, yous...   \n2                            [bihday, yoyouare, majesty]   \n3      [model, love, you, take, with, you, all, the, ...   \n4            [factsgrinyouide, society, now, motivation]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrinned, today, in, ohio, oh...   \n49157  [happy, at, woarek, confeareence, areigrinht, ...   \n49158  [my, songrin, so, grinlad, fareee, download, s...   \n\n                                    tweet_token_filtered  \n0      [fatheare, dysfyounctional, selfish, dareagrin...  \n1      [thanks, foare, lyft, careedit, youse, cayouse...  \n2                            [bihday, yoyouare, majesty]  \n3                      [model, love, take, time, youare]  \n4                 [factsgrinyouide, society, motivation]  \n...                                                  ...  \n49154  [thoyougrinht, factoarey, left, areigrinht, po...  \n49155  [feelingrin, like, mearemaid, haiareflip, neve...  \n49156  [hillaarey, campaigrinned, today, ohio, oh, go...  \n49157  [happy, woarek, confeareence, areigrinht, mind...  \n49158  [songrin, grinlad, fareee, download, shoegrina...  \n\n[49159 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_token</th>\n      <th>tweet_token_filtered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when fatheare is dysfyounctional and is so sel...</td>\n      <td>[when, fatheare, is, dysfyounctional, and, is,...</td>\n      <td>[fatheare, dysfyounctional, selfish, dareagrin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare lyft careedit cannot youse cayous...</td>\n      <td>[thanks, foare, lyft, careedit, can, not, yous...</td>\n      <td>[thanks, foare, lyft, careedit, youse, cayouse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n      <td>[bihday, yoyouare, majesty]</td>\n      <td>[bihday, yoyouare, majesty]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in y...</td>\n      <td>[model, love, you, take, with, you, all, the, ...</td>\n      <td>[model, love, take, time, youare]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide society now motivation</td>\n      <td>[factsgrinyouide, society, now, motivation]</td>\n      <td>[factsgrinyouide, society, motivation]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey left areigrinht polaare...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like mearemaid haiareflip nevearear...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey campaigrinned today in ohio oh my go...</td>\n      <td>[hillaarey, campaigrinned, today, in, ohio, oh...</td>\n      <td>[hillaarey, campaigrinned, today, ohio, oh, go...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy at woarek confeareence areigrinht mindse...</td>\n      <td>[happy, at, woarek, confeareence, areigrinht, ...</td>\n      <td>[happy, woarek, confeareence, areigrinht, mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my songrin so grinlad fareee download shoegrin...</td>\n      <td>[my, songrin, so, grinlad, fareee, download, s...</td>\n      <td>[songrin, grinlad, fareee, download, shoegrina...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_token_filtered'] = [[word for word in text if word not in stop_words] for text in df.tweet_token]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet  \\\n0          1    0.0  when fatheare is dysfyounctional and is so sel...   \n1          2    0.0  thanks foare lyft careedit cannot youse cayous...   \n2          3    0.0                            bihday yoyouare majesty   \n3          4    0.0  model love you take with you all the time in y...   \n4          5    0.0             factsgrinyouide society now motivation   \n...      ...    ...                                                ...   \n49154  49155    NaN  thoyougrinht factoarey left areigrinht polaare...   \n49155  49156    NaN  feelingrin like mearemaid haiareflip nevearear...   \n49156  49157    NaN  hillaarey campaigrinned today in ohio oh my go...   \n49157  49158    NaN  happy at woarek confeareence areigrinht mindse...   \n49158  49159    NaN  my songrin so grinlad fareee download shoegrin...   \n\n                                             tweet_token  \\\n0      [when, fatheare, is, dysfyounctional, and, is,...   \n1      [thanks, foare, lyft, careedit, can, not, yous...   \n2                            [bihday, yoyouare, majesty]   \n3      [model, love, you, take, with, you, all, the, ...   \n4            [factsgrinyouide, society, now, motivation]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrinned, today, in, ohio, oh...   \n49157  [happy, at, woarek, confeareence, areigrinht, ...   \n49158  [my, songrin, so, grinlad, fareee, download, s...   \n\n                                    tweet_token_filtered  \\\n0      [fatheare, dysfyounctional, selfish, dareagrin...   \n1      [thanks, foare, lyft, careedit, youse, cayouse...   \n2                            [bihday, yoyouare, majesty]   \n3                      [model, love, take, time, youare]   \n4                 [factsgrinyouide, society, motivation]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrinned, today, ohio, oh, go...   \n49157  [happy, woarek, confeareence, areigrinht, mind...   \n49158  [songrin, grinlad, fareee, download, shoegrina...   \n\n                                           tweet_stemmed  \n0      [fathear, dysfyounct, selfish, dareagrin, kid,...  \n1      [thank, foar, lyft, careedit, yous, cayous, of...  \n2                             [bihday, yoyouar, majesti]  \n3                       [model, love, take, time, youar]  \n4                       [factsgrinyouid, societi, motiv]  \n...                                                  ...  \n49154  [thoyougrinht, factoarey, left, areigrinht, po...  \n49155  [feelingrin, like, mearemaid, haiareflip, neve...  \n49156  [hillaarey, campaigrin, today, ohio, oh, god, ...  \n49157  [happi, woarek, confear, areigrinht, mindset, ...  \n49158  [songrin, grinlad, faree, download, shoegrinaz...  \n\n[49159 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_token</th>\n      <th>tweet_token_filtered</th>\n      <th>tweet_stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when fatheare is dysfyounctional and is so sel...</td>\n      <td>[when, fatheare, is, dysfyounctional, and, is,...</td>\n      <td>[fatheare, dysfyounctional, selfish, dareagrin...</td>\n      <td>[fathear, dysfyounct, selfish, dareagrin, kid,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare lyft careedit cannot youse cayous...</td>\n      <td>[thanks, foare, lyft, careedit, can, not, yous...</td>\n      <td>[thanks, foare, lyft, careedit, youse, cayouse...</td>\n      <td>[thank, foar, lyft, careedit, yous, cayous, of...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n      <td>[bihday, yoyouare, majesty]</td>\n      <td>[bihday, yoyouare, majesty]</td>\n      <td>[bihday, yoyouar, majesti]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in y...</td>\n      <td>[model, love, you, take, with, you, all, the, ...</td>\n      <td>[model, love, take, time, youare]</td>\n      <td>[model, love, take, time, youar]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide society now motivation</td>\n      <td>[factsgrinyouide, society, now, motivation]</td>\n      <td>[factsgrinyouide, society, motivation]</td>\n      <td>[factsgrinyouid, societi, motiv]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey left areigrinht polaare...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like mearemaid haiareflip nevearear...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey campaigrinned today in ohio oh my go...</td>\n      <td>[hillaarey, campaigrinned, today, in, ohio, oh...</td>\n      <td>[hillaarey, campaigrinned, today, ohio, oh, go...</td>\n      <td>[hillaarey, campaigrin, today, ohio, oh, god, ...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy at woarek confeareence areigrinht mindse...</td>\n      <td>[happy, at, woarek, confeareence, areigrinht, ...</td>\n      <td>[happy, woarek, confeareence, areigrinht, mind...</td>\n      <td>[happi, woarek, confear, areigrinht, mindset, ...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my songrin so grinlad fareee download shoegrin...</td>\n      <td>[my, songrin, so, grinlad, fareee, download, s...</td>\n      <td>[songrin, grinlad, fareee, download, shoegrina...</td>\n      <td>[songrin, grinlad, faree, download, shoegrinaz...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "df['tweet_stemmed'] = [[stemmer.stem(plural) for plural in plurals] for plurals in df.tweet_token_filtered]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label                                              tweet  \\\n0          1    0.0  when fatheare is dysfyounctional and is so sel...   \n1          2    0.0  thanks foare lyft careedit cannot youse cayous...   \n2          3    0.0                            bihday yoyouare majesty   \n3          4    0.0  model love you take with you all the time in y...   \n4          5    0.0             factsgrinyouide society now motivation   \n...      ...    ...                                                ...   \n49154  49155    NaN  thoyougrinht factoarey left areigrinht polaare...   \n49155  49156    NaN  feelingrin like mearemaid haiareflip nevearear...   \n49156  49157    NaN  hillaarey campaigrinned today in ohio oh my go...   \n49157  49158    NaN  happy at woarek confeareence areigrinht mindse...   \n49158  49159    NaN  my songrin so grinlad fareee download shoegrin...   \n\n                                             tweet_token  \\\n0      [when, fatheare, is, dysfyounctional, and, is,...   \n1      [thanks, foare, lyft, careedit, can, not, yous...   \n2                            [bihday, yoyouare, majesty]   \n3      [model, love, you, take, with, you, all, the, ...   \n4            [factsgrinyouide, society, now, motivation]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrinned, today, in, ohio, oh...   \n49157  [happy, at, woarek, confeareence, areigrinht, ...   \n49158  [my, songrin, so, grinlad, fareee, download, s...   \n\n                                    tweet_token_filtered  \\\n0      [fatheare, dysfyounctional, selfish, dareagrin...   \n1      [thanks, foare, lyft, careedit, youse, cayouse...   \n2                            [bihday, yoyouare, majesty]   \n3                      [model, love, take, time, youare]   \n4                 [factsgrinyouide, society, motivation]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrinned, today, ohio, oh, go...   \n49157  [happy, woarek, confeareence, areigrinht, mind...   \n49158  [songrin, grinlad, fareee, download, shoegrina...   \n\n                                           tweet_stemmed  \\\n0      [fathear, dysfyounct, selfish, dareagrin, kid,...   \n1      [thank, foar, lyft, careedit, yous, cayous, of...   \n2                             [bihday, yoyouar, majesti]   \n3                       [model, love, take, time, youar]   \n4                       [factsgrinyouid, societi, motiv]   \n...                                                  ...   \n49154  [thoyougrinht, factoarey, left, areigrinht, po...   \n49155  [feelingrin, like, mearemaid, haiareflip, neve...   \n49156  [hillaarey, campaigrin, today, ohio, oh, god, ...   \n49157  [happi, woarek, confear, areigrinht, mindset, ...   \n49158  [songrin, grinlad, faree, download, shoegrinaz...   \n\n                                        tweet_lemmatized  \n0      [fatheare, dysfyounctional, selfish, dareagrin...  \n1      [thanks, foare, lyft, careedit, youse, cayouse...  \n2                            [bihday, yoyouare, majesty]  \n3                      [model, love, take, time, youare]  \n4                 [factsgrinyouide, society, motivation]  \n...                                                  ...  \n49154  [thoyougrinht, factoarey, left, areigrinht, po...  \n49155  [feelingrin, like, mearemaid, haiareflip, neve...  \n49156  [hillaarey, campaigrinned, today, ohio, oh, go...  \n49157  [happy, woarek, confeareence, areigrinht, mind...  \n49158  [songrin, grinlad, fareee, download, shoegrina...  \n\n[49159 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>tweet_token</th>\n      <th>tweet_token_filtered</th>\n      <th>tweet_stemmed</th>\n      <th>tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>when fatheare is dysfyounctional and is so sel...</td>\n      <td>[when, fatheare, is, dysfyounctional, and, is,...</td>\n      <td>[fatheare, dysfyounctional, selfish, dareagrin...</td>\n      <td>[fathear, dysfyounct, selfish, dareagrin, kid,...</td>\n      <td>[fatheare, dysfyounctional, selfish, dareagrin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>thanks foare lyft careedit cannot youse cayous...</td>\n      <td>[thanks, foare, lyft, careedit, can, not, yous...</td>\n      <td>[thanks, foare, lyft, careedit, youse, cayouse...</td>\n      <td>[thank, foar, lyft, careedit, yous, cayous, of...</td>\n      <td>[thanks, foare, lyft, careedit, youse, cayouse...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>bihday yoyouare majesty</td>\n      <td>[bihday, yoyouare, majesty]</td>\n      <td>[bihday, yoyouare, majesty]</td>\n      <td>[bihday, yoyouar, majesti]</td>\n      <td>[bihday, yoyouare, majesty]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>model love you take with you all the time in y...</td>\n      <td>[model, love, you, take, with, you, all, the, ...</td>\n      <td>[model, love, take, time, youare]</td>\n      <td>[model, love, take, time, youar]</td>\n      <td>[model, love, take, time, youare]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>factsgrinyouide society now motivation</td>\n      <td>[factsgrinyouide, society, now, motivation]</td>\n      <td>[factsgrinyouide, society, motivation]</td>\n      <td>[factsgrinyouid, societi, motiv]</td>\n      <td>[factsgrinyouide, society, motivation]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>49155</td>\n      <td>NaN</td>\n      <td>thoyougrinht factoarey left areigrinht polaare...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n      <td>[thoyougrinht, factoarey, left, areigrinht, po...</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>49156</td>\n      <td>NaN</td>\n      <td>feelingrin like mearemaid haiareflip nevearear...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n      <td>[feelingrin, like, mearemaid, haiareflip, neve...</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>49157</td>\n      <td>NaN</td>\n      <td>hillaarey campaigrinned today in ohio oh my go...</td>\n      <td>[hillaarey, campaigrinned, today, in, ohio, oh...</td>\n      <td>[hillaarey, campaigrinned, today, ohio, oh, go...</td>\n      <td>[hillaarey, campaigrin, today, ohio, oh, god, ...</td>\n      <td>[hillaarey, campaigrinned, today, ohio, oh, go...</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>49158</td>\n      <td>NaN</td>\n      <td>happy at woarek confeareence areigrinht mindse...</td>\n      <td>[happy, at, woarek, confeareence, areigrinht, ...</td>\n      <td>[happy, woarek, confeareence, areigrinht, mind...</td>\n      <td>[happi, woarek, confear, areigrinht, mindset, ...</td>\n      <td>[happy, woarek, confeareence, areigrinht, mind...</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>49159</td>\n      <td>NaN</td>\n      <td>my songrin so grinlad fareee download shoegrin...</td>\n      <td>[my, songrin, so, grinlad, fareee, download, s...</td>\n      <td>[songrin, grinlad, fareee, download, shoegrina...</td>\n      <td>[songrin, grinlad, faree, download, shoegrinaz...</td>\n      <td>[songrin, grinlad, fareee, download, shoegrina...</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "df['tweet_lemmatized'] = [[lemmatizer.lemmatize(plural) for plural in plurals] for plurals in df.tweet_token_filtered]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('dummy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=0.9, max_features=1000, stop_words='english')\n",
    "tfidf_vecotizer = TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0        fathear dysfyounct selfish dareagrin kid dysfy...\n1        thank foar lyft careedit yous cayous offear wh...\n2                                   bihday yoyouar majesti\n3                               model love take time youar\n4                             factsgrinyouid societi motiv\n                               ...                        \n49154    thoyougrinht factoarey left areigrinht polaare...\n49155    feelingrin like mearemaid haiareflip nevearear...\n49156    hillaarey campaigrin today ohio oh god yous wo...\n49157    happi woarek confear areigrinht mindset lead s...\n49158    songrin grinlad faree download shoegrinaz newm...\nName: tweet_stemmed, Length: 49159, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_to_str(list):\n",
    "    return ' '.join(list)\n",
    "df.tweet_stemmed.apply(list_to_str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "count_stemmed_bag = count_vectorizer.fit_transform(df.tweet_stemmed.apply(list_to_str))\n",
    "count_lemmatized_bag = count_vectorizer.fit_transform(df.tweet_lemmatized.apply(list_to_str))\n",
    "tfidf_stemmed_bag = tfidf_vecotizer.fit_transform(df.tweet_stemmed.apply(list_to_str))\n",
    "tfidf_lemmatized_bag = tfidf_vecotizer.fit_transform(df.tweet_lemmatized.apply(list_to_str))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accoyount  \\\n0                0      0           0     0        0             0          0   \n1                0      0           0     0        0             0          0   \n2                0      0           0     0        0             0          0   \n3                0      0           0     0        0             0          0   \n4                0      0           0     0        0             0          0   \n...            ...    ...         ...   ...      ...           ...        ...   \n49154            0      0           0     0        0             0          0   \n49155            0      0           0     0        0             0          0   \n49156            0      0           0     0        0             0          0   \n49157            0      0           0     0        0             0          0   \n49158            0      0           0     0        0             0          0   \n\n       act  action  actoare  ...  youstomeares  yout  youte  yoyou  yoyouare  \\\n0        0       0        0  ...             0     0      0      0         0   \n1        0       0        0  ...             0     0      0      0         0   \n2        0       0        0  ...             0     0      0      0         0   \n3        0       0        0  ...             0     0      0      0         0   \n4        0       0        0  ...             0     0      0      0         0   \n...    ...     ...      ...  ...           ...   ...    ...    ...       ...   \n49154    0       0        0  ...             0     0      0      0         0   \n49155    0       0        0  ...             0     0      0      0         0   \n49156    0       0        0  ...             0     0      0      0         0   \n49157    0       0        0  ...             0     0      0      0         0   \n49158    0       0        0  ...             0     0      0      0         0   \n\n       yoyouares  yoyouareself  yoyoungrin  yoyoutyoube  yyoummy  \n0              0             0           0            0        0  \n1              0             0           0            0        0  \n2              1             0           0            0        0  \n3              0             0           0            0        0  \n4              0             0           0            0        0  \n...          ...           ...         ...          ...      ...  \n49154          0             0           0            0        0  \n49155          0             0           0            0        0  \n49156          0             0           0            0        0  \n49157          0             0           0            0        0  \n49158          0             0           0            0        0  \n\n[49159 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aareareived</th>\n      <th>aaree</th>\n      <th>aareoyound</th>\n      <th>able</th>\n      <th>aboyout</th>\n      <th>absolyoutely</th>\n      <th>accoyount</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actoare</th>\n      <th>...</th>\n      <th>youstomeares</th>\n      <th>yout</th>\n      <th>youte</th>\n      <th>yoyou</th>\n      <th>yoyouare</th>\n      <th>yoyouares</th>\n      <th>yoyouareself</th>\n      <th>yoyoungrin</th>\n      <th>yoyoutyoube</th>\n      <th>yyoummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_stemmed_bag.toarray(), columns = count_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accoyount  \\\n0                0      0           0     0        0             0          0   \n1                0      0           0     0        0             0          0   \n2                0      0           0     0        0             0          0   \n3                0      0           0     0        0             0          0   \n4                0      0           0     0        0             0          0   \n...            ...    ...         ...   ...      ...           ...        ...   \n49154            0      0           0     0        0             0          0   \n49155            0      0           0     0        0             0          0   \n49156            0      0           0     0        0             0          0   \n49157            0      0           0     0        0             0          0   \n49158            0      0           0     0        0             0          0   \n\n       act  action  actoare  ...  youstomeares  yout  youte  yoyou  yoyouare  \\\n0        0       0        0  ...             0     0      0      0         0   \n1        0       0        0  ...             0     0      0      0         0   \n2        0       0        0  ...             0     0      0      0         1   \n3        0       0        0  ...             0     0      0      0         0   \n4        0       0        0  ...             0     0      0      0         0   \n...    ...     ...      ...  ...           ...   ...    ...    ...       ...   \n49154    0       0        0  ...             0     0      0      0         0   \n49155    0       0        0  ...             0     0      0      0         0   \n49156    0       0        0  ...             0     0      0      0         0   \n49157    0       0        0  ...             0     0      0      0         0   \n49158    0       0        0  ...             0     0      0      0         0   \n\n       yoyouares  yoyouareself  yoyoungrin  yoyoutyoube  yyoummy  \n0              0             0           0            0        0  \n1              0             0           0            0        0  \n2              0             0           0            0        0  \n3              0             0           0            0        0  \n4              0             0           0            0        0  \n...          ...           ...         ...          ...      ...  \n49154          0             0           0            0        0  \n49155          0             0           0            0        0  \n49156          0             0           0            0        0  \n49157          0             0           0            0        0  \n49158          0             0           0            0        0  \n\n[49159 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aareareived</th>\n      <th>aaree</th>\n      <th>aareoyound</th>\n      <th>able</th>\n      <th>aboyout</th>\n      <th>absolyoutely</th>\n      <th>accoyount</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actoare</th>\n      <th>...</th>\n      <th>youstomeares</th>\n      <th>yout</th>\n      <th>youte</th>\n      <th>yoyou</th>\n      <th>yoyouare</th>\n      <th>yoyouares</th>\n      <th>yoyouareself</th>\n      <th>yoyoungrin</th>\n      <th>yoyoutyoube</th>\n      <th>yyoummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_lemmatized_bag.toarray(), columns = count_vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accoyount  \\\n0              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n1              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n2              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n3              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n4              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n...            ...    ...         ...   ...      ...           ...        ...   \n49154          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49155          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49156          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49157          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49158          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n\n       act  action  actoare  ...  youstomeares  yout  youte  yoyou  yoyouare  \\\n0      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n1      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n2      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n3      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n4      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n...    ...     ...      ...  ...           ...   ...    ...    ...       ...   \n49154  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n49155  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n49156  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n49157  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n49158  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0       0.0   \n\n       yoyouares  yoyouareself  yoyoungrin  yoyoutyoube  yyoummy  \n0       0.000000           0.0         0.0          0.0      0.0  \n1       0.000000           0.0         0.0          0.0      0.0  \n2       0.637825           0.0         0.0          0.0      0.0  \n3       0.000000           0.0         0.0          0.0      0.0  \n4       0.000000           0.0         0.0          0.0      0.0  \n...          ...           ...         ...          ...      ...  \n49154   0.000000           0.0         0.0          0.0      0.0  \n49155   0.000000           0.0         0.0          0.0      0.0  \n49156   0.000000           0.0         0.0          0.0      0.0  \n49157   0.000000           0.0         0.0          0.0      0.0  \n49158   0.000000           0.0         0.0          0.0      0.0  \n\n[49159 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aareareived</th>\n      <th>aaree</th>\n      <th>aareoyound</th>\n      <th>able</th>\n      <th>aboyout</th>\n      <th>absolyoutely</th>\n      <th>accoyount</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actoare</th>\n      <th>...</th>\n      <th>youstomeares</th>\n      <th>yout</th>\n      <th>youte</th>\n      <th>yoyou</th>\n      <th>yoyouare</th>\n      <th>yoyouares</th>\n      <th>yoyouareself</th>\n      <th>yoyoungrin</th>\n      <th>yoyoutyoube</th>\n      <th>yyoummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.637825</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_stemmed_bag.toarray(), columns = tfidf_vecotizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "       aareareived  aaree  aareoyound  able  aboyout  absolyoutely  accoyount  \\\n0              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n1              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n2              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n3              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n4              0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n...            ...    ...         ...   ...      ...           ...        ...   \n49154          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49155          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49156          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49157          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n49158          0.0    0.0         0.0   0.0      0.0           0.0        0.0   \n\n       act  action  actoare  ...  youstomeares  yout  youte  yoyou  yoyouare  \\\n0      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n1      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n2      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.639302   \n3      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n4      0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n...    ...     ...      ...  ...           ...   ...    ...    ...       ...   \n49154  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n49155  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n49156  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n49157  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n49158  0.0     0.0      0.0  ...           0.0   0.0    0.0    0.0  0.000000   \n\n       yoyouares  yoyouareself  yoyoungrin  yoyoutyoube  yyoummy  \n0            0.0           0.0         0.0          0.0      0.0  \n1            0.0           0.0         0.0          0.0      0.0  \n2            0.0           0.0         0.0          0.0      0.0  \n3            0.0           0.0         0.0          0.0      0.0  \n4            0.0           0.0         0.0          0.0      0.0  \n...          ...           ...         ...          ...      ...  \n49154        0.0           0.0         0.0          0.0      0.0  \n49155        0.0           0.0         0.0          0.0      0.0  \n49156        0.0           0.0         0.0          0.0      0.0  \n49157        0.0           0.0         0.0          0.0      0.0  \n49158        0.0           0.0         0.0          0.0      0.0  \n\n[49159 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aareareived</th>\n      <th>aaree</th>\n      <th>aareoyound</th>\n      <th>able</th>\n      <th>aboyout</th>\n      <th>absolyoutely</th>\n      <th>accoyount</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actoare</th>\n      <th>...</th>\n      <th>youstomeares</th>\n      <th>yout</th>\n      <th>youte</th>\n      <th>yoyou</th>\n      <th>yoyouare</th>\n      <th>yoyouares</th>\n      <th>yoyouareself</th>\n      <th>yoyoungrin</th>\n      <th>yoyoutyoube</th>\n      <th>yyoummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.639302</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49154</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49155</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49156</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49157</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49158</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>49159 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_lemmatized_bag.toarray(), columns = tfidf_vecotizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text       label\n0  Stuning even for the non-gamer: This sound tra...  __label__2\n1  The best soundtrack ever to anything.: I'm rea...  __label__2\n2  Amazing!: This soundtrack is my favorite music...  __label__2\n3  Excellent Soundtrack: I truly like this soundt...  __label__2\n4  Remember, Pull Your Jaw Off The Floor After He...  __label__2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n      <td>__label__2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_vectorizer_score(trained_vectorizer):\n",
    "    train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "    # labelEncode целевую переменную\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    train_y = encoder.fit_transform(train_y)\n",
    "    valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "    xtrain_count = trained_vectorizer.transform(train_x)\n",
    "    xvalid_count = trained_vectorizer.transform(valid_x)\n",
    "\n",
    "    classifier = linear_model.LogisticRegression()\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "    return accuracy_score(valid_y, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def grid_search_count_vectorizer(max_df_list, max_features_list):\n",
    "    vectorizers_name = []\n",
    "    vectorizers_accuracy = []\n",
    "    for max_df in max_df_list:\n",
    "        for max_features in max_features_list:\n",
    "            count_vectorizer = CountVectorizer(max_df=max_df, max_features=max_features, stop_words='english')\n",
    "            count_vectorizer.fit(df.tweet_lemmatized.apply(list_to_str))\n",
    "            vectorizers_name.append(f'count_v_{max_df}_{max_features}')\n",
    "            vectorizers_accuracy.append(get_vectorizer_score(count_vectorizer))\n",
    "    return max(vectorizers_accuracy), vectorizers_name, vectorizers_accuracy\n",
    "\n",
    "def grid_search_tfidf_vectorizer(max_df_list, max_features_list):\n",
    "    vectorizers_name = []\n",
    "    vectorizers_accuracy = []\n",
    "    for max_df in max_df_list:\n",
    "        for max_features in max_features_list:\n",
    "            tfidf_vecotizer = TfidfVectorizer(max_df=max_df, max_features=max_features, stop_words='english')\n",
    "            tfidf_vecotizer.fit(df.tweet_lemmatized.apply(list_to_str))\n",
    "            vectorizers_name.append(f'tfidf_{max_df}_{max_features}')\n",
    "            vectorizers_accuracy.append(get_vectorizer_score(tfidf_vecotizer))\n",
    "    return max(vectorizers_accuracy), vectorizers_name, vectorizers_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7576, 0.7652)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "df_list = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "max_features = [200, 400, 600, 1000, 3000, 5000, 10000]\n",
    "best_count_acc, count_v_params, count_v_metrics = grid_search_count_vectorizer(df_list, max_features)\n",
    "best_tfidf_acc, tfidf_params, tfidf_metrics = grid_search_tfidf_vectorizer(df_list, max_features)\n",
    "best_count_acc, best_tfidf_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                   accuracy\ncount_v_0.4_200      0.6112\ncount_v_0.4_400      0.6696\ncount_v_0.4_600      0.6584\ncount_v_0.4_1000     0.6852\ncount_v_0.4_3000     0.7228\ncount_v_0.4_5000     0.7404\ncount_v_0.4_10000    0.7400\ncount_v_0.5_200      0.6184\ncount_v_0.5_400      0.6664\ncount_v_0.5_600      0.6612\ncount_v_0.5_1000     0.6764\ncount_v_0.5_3000     0.7388\ncount_v_0.5_5000     0.7488\ncount_v_0.5_10000    0.7484\ncount_v_0.6_200      0.6364\ncount_v_0.6_400      0.6504\ncount_v_0.6_600      0.6520\ncount_v_0.6_1000     0.6816\ncount_v_0.6_3000     0.7180\ncount_v_0.6_5000     0.7424\ncount_v_0.6_10000    0.7448\ncount_v_0.7_200      0.6284\ncount_v_0.7_400      0.6488\ncount_v_0.7_600      0.6432\ncount_v_0.7_1000     0.6732\ncount_v_0.7_3000     0.7268\ncount_v_0.7_5000     0.7464\ncount_v_0.7_10000    0.7488\ncount_v_0.8_200      0.6352\ncount_v_0.8_400      0.6496\ncount_v_0.8_600      0.6756\ncount_v_0.8_1000     0.6924\ncount_v_0.8_3000     0.7268\ncount_v_0.8_5000     0.7576\ncount_v_0.8_10000    0.7436\ncount_v_0.9_200      0.6212\ncount_v_0.9_400      0.6616\ncount_v_0.9_600      0.6600\ncount_v_0.9_1000     0.6864\ncount_v_0.9_3000     0.7316\ncount_v_0.9_5000     0.7460\ncount_v_0.9_10000    0.7468",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count_v_0.4_200</th>\n      <td>0.6112</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_400</th>\n      <td>0.6696</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_600</th>\n      <td>0.6584</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_1000</th>\n      <td>0.6852</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_3000</th>\n      <td>0.7228</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_5000</th>\n      <td>0.7404</td>\n    </tr>\n    <tr>\n      <th>count_v_0.4_10000</th>\n      <td>0.7400</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_200</th>\n      <td>0.6184</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_400</th>\n      <td>0.6664</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_600</th>\n      <td>0.6612</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_1000</th>\n      <td>0.6764</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_3000</th>\n      <td>0.7388</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_5000</th>\n      <td>0.7488</td>\n    </tr>\n    <tr>\n      <th>count_v_0.5_10000</th>\n      <td>0.7484</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_200</th>\n      <td>0.6364</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_400</th>\n      <td>0.6504</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_600</th>\n      <td>0.6520</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_1000</th>\n      <td>0.6816</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_3000</th>\n      <td>0.7180</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_5000</th>\n      <td>0.7424</td>\n    </tr>\n    <tr>\n      <th>count_v_0.6_10000</th>\n      <td>0.7448</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_200</th>\n      <td>0.6284</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_400</th>\n      <td>0.6488</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_600</th>\n      <td>0.6432</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_1000</th>\n      <td>0.6732</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_3000</th>\n      <td>0.7268</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_5000</th>\n      <td>0.7464</td>\n    </tr>\n    <tr>\n      <th>count_v_0.7_10000</th>\n      <td>0.7488</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_200</th>\n      <td>0.6352</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_400</th>\n      <td>0.6496</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_600</th>\n      <td>0.6756</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_1000</th>\n      <td>0.6924</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_3000</th>\n      <td>0.7268</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_5000</th>\n      <td>0.7576</td>\n    </tr>\n    <tr>\n      <th>count_v_0.8_10000</th>\n      <td>0.7436</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_200</th>\n      <td>0.6212</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_400</th>\n      <td>0.6616</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_600</th>\n      <td>0.6600</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_1000</th>\n      <td>0.6864</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_3000</th>\n      <td>0.7316</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_5000</th>\n      <td>0.7460</td>\n    </tr>\n    <tr>\n      <th>count_v_0.9_10000</th>\n      <td>0.7468</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_vectorizer scores\n",
    "pd.DataFrame({'accuracy': count_v_metrics}, index=count_v_params)\n",
    "#Best params max_df = 0.8, max_features=5000 acc=0.7576"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                 accuracy\ntfidf_0.4_200      0.6304\ntfidf_0.4_400      0.6564\ntfidf_0.4_600      0.6644\ntfidf_0.4_1000     0.6880\ntfidf_0.4_3000     0.7356\ntfidf_0.4_5000     0.7420\ntfidf_0.4_10000    0.7624\ntfidf_0.5_200      0.6296\ntfidf_0.5_400      0.6668\ntfidf_0.5_600      0.6664\ntfidf_0.5_1000     0.6972\ntfidf_0.5_3000     0.7352\ntfidf_0.5_5000     0.7456\ntfidf_0.5_10000    0.7556\ntfidf_0.6_200      0.6324\ntfidf_0.6_400      0.6560\ntfidf_0.6_600      0.6592\ntfidf_0.6_1000     0.6972\ntfidf_0.6_3000     0.7328\ntfidf_0.6_5000     0.7396\ntfidf_0.6_10000    0.7516\ntfidf_0.7_200      0.6180\ntfidf_0.7_400      0.6492\ntfidf_0.7_600      0.6572\ntfidf_0.7_1000     0.6736\ntfidf_0.7_3000     0.7436\ntfidf_0.7_5000     0.7444\ntfidf_0.7_10000    0.7556\ntfidf_0.8_200      0.6128\ntfidf_0.8_400      0.6576\ntfidf_0.8_600      0.6644\ntfidf_0.8_1000     0.6960\ntfidf_0.8_3000     0.7464\ntfidf_0.8_5000     0.7652\ntfidf_0.8_10000    0.7468\ntfidf_0.9_200      0.6276\ntfidf_0.9_400      0.6532\ntfidf_0.9_600      0.6524\ntfidf_0.9_1000     0.6936\ntfidf_0.9_3000     0.7272\ntfidf_0.9_5000     0.7400\ntfidf_0.9_10000    0.7584",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tfidf_0.4_200</th>\n      <td>0.6304</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_400</th>\n      <td>0.6564</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_600</th>\n      <td>0.6644</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_1000</th>\n      <td>0.6880</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_3000</th>\n      <td>0.7356</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_5000</th>\n      <td>0.7420</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.4_10000</th>\n      <td>0.7624</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_200</th>\n      <td>0.6296</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_400</th>\n      <td>0.6668</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_600</th>\n      <td>0.6664</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_1000</th>\n      <td>0.6972</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_3000</th>\n      <td>0.7352</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_5000</th>\n      <td>0.7456</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.5_10000</th>\n      <td>0.7556</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_200</th>\n      <td>0.6324</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_400</th>\n      <td>0.6560</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_600</th>\n      <td>0.6592</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_1000</th>\n      <td>0.6972</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_3000</th>\n      <td>0.7328</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_5000</th>\n      <td>0.7396</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.6_10000</th>\n      <td>0.7516</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_200</th>\n      <td>0.6180</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_400</th>\n      <td>0.6492</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_600</th>\n      <td>0.6572</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_1000</th>\n      <td>0.6736</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_3000</th>\n      <td>0.7436</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_5000</th>\n      <td>0.7444</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.7_10000</th>\n      <td>0.7556</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_200</th>\n      <td>0.6128</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_400</th>\n      <td>0.6576</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_600</th>\n      <td>0.6644</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_1000</th>\n      <td>0.6960</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_3000</th>\n      <td>0.7464</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_5000</th>\n      <td>0.7652</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.8_10000</th>\n      <td>0.7468</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_200</th>\n      <td>0.6276</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_400</th>\n      <td>0.6532</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_600</th>\n      <td>0.6524</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_1000</th>\n      <td>0.6936</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_3000</th>\n      <td>0.7272</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_5000</th>\n      <td>0.7400</td>\n    </tr>\n    <tr>\n      <th>tfidf_0.9_10000</th>\n      <td>0.7584</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf_scores\n",
    "pd.DataFrame({'accuracy': tfidf_metrics}, index=tfidf_params)\n",
    "#Best params params max_df = 0.8, max_features=5000 acc=0.7652"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из перебора параметров векторайзера видно, что оптимальное значение отсечения датафрейма от 0.7 до 0.9, большое количество фичей замедляет обучение модели, но дает прирост к скору. Конечно скор зависит в большей степени от того как сама модель обучится, т.к после обучения векторайзера модель учится заново и у нее будут другие веса, так что эти показатели не совсем эффективны, но зависимость все равно прослеживается"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PCA испробуем на изначальных параметрах векторайзера (df_max = 0.9, feats = 1000), и сравним скор с использованием декомпозиции и без нее. Перебор скора не вижу смысла делать для этого. Возьму лемматизированный мешок, для двух видов векторайзера"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#Продублирую код из функции и добавлю PCA\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "#count_vectorizer + PCA\n",
    "xtrain_count = count_vectorizer.transform(train_x)\n",
    "xvalid_count = count_vectorizer.transform(valid_x)\n",
    "xtrain_pca_count = pca.fit_transform(pd.DataFrame(xtrain_count.toarray(), columns = count_vecotizer.get_feature_names_out()))\n",
    "xvalid_pca_count = pca.fit_transform(pd.DataFrame(xvalid_count.toarray(), columns = count_vecotizer.get_feature_names_out()))\n",
    "\n",
    "#tfidf_vectorizer + PCA\n",
    "xtrain_tfidf = tfidf_vecotizer.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vecotizer.transform(valid_x)\n",
    "xtrain_pca_tfidf = pca.fit_transform(pd.DataFrame(xtrain_tfidf.toarray(), columns = count_vecotizer.get_feature_names_out()))\n",
    "xvalid_pca_tfidf = pca.fit_transform(pd.DataFrame(xvalid_tfidf.toarray(), columns = count_vecotizer.get_feature_names_out()))\n",
    "\n",
    "#Обучаем тут только PCA векторайзеры, для обычных есть функция уже через нее сделаю\n",
    "classifier_count = linear_model.LogisticRegression()\n",
    "classifier_count.fit(xtrain_pca_count, train_y)\n",
    "predictions_count = classifier_count.predict(xvalid_pca_count)\n",
    "accuracy_count = accuracy_score(valid_y, predictions_count)\n",
    "\n",
    "classifier_tfidf = linear_model.LogisticRegression()\n",
    "classifier_tfidf.fit(xtrain_pca_tfidf, train_y)\n",
    "predictions_tfidf = classifier_tfidf.predict(xvalid_pca_tfidf)\n",
    "accuracy_tfidf = accuracy_score(valid_y, predictions_tfidf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6808, 0.6636)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Попарно выведу обычный count vectorizer и PCA vectorizer\n",
    "get_vectorizer_score(count_vectorizer), accuracy_count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6868, 0.6724)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vectorizer_score(tfidf_vecotizer), accuracy_tfidf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод очевиден PCA снижает скор, но очень незначительно. Зато количество признаков с 1000 снижается аж до 2, это понятно т.к матрицы сильно разряженные, в этом мало смысла"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
